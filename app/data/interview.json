[
  {
    "id": "llm_interview_001",
    "question": "トークン化とは何ですか？なぜLLMにとって重要なのですか？",
    "answer": {
      "definition": "トークン化とは、テキストデータを意味のある最小単位（トークン）に分割する処理のことです。単語、サブワード、文字などの単位に分割されます。",
      "importance": "LLMは生のテキストを直接処理できないため、数値表現に変換する必要があります。トークン化は、テキストを扱いやすい単位に分割し、各トークンを数値IDに変換することで、モデルが処理可能な形式にします。",
      "mechanism": "1. テキストを前処理（正規化）\n2. 語彙に基づいて分割アルゴリズムを適用\n3. 各トークンを語彙内のIDに変換\n4. 特殊トークン（[CLS]、[SEP]など）を追加",
      "key_points": [
        "語彙サイズとモデル性能のトレードオフ",
        "未知語（OOV）問題の解決",
        "多言語対応の実現",
        "計算効率の向上"
      ],
      "examples": [
        "WordPiece: 'playing' → ['play', '##ing']",
        "BPE: 'lowest' → ['low', 'est']",
        "SentencePiece: 言語に依存しない分割"
      ],
      "applications": "機械翻訳、テキスト生成、感情分析、質問応答システムなど、すべてのNLPタスクの前処理として使用されます。",
      "advantages": "1. 語彙サイズの最適化\n2. 未知語の削減\n3. 形態素解析が不要\n4. 言語非依存の処理が可能",
      "limitations": "1. トークン境界が意味的境界と一致しない場合がある\n2. 同じ単語でも文脈によって異なる分割になる可能性\n3. 計算コストとメモリ使用量の増加",
      "formulas": [],
      "related_concepts": "BPE（Byte Pair Encoding）、WordPiece、SentencePiece、Unigram Language Model",
      "additional_notes": "最新のLLMでは、BPEやSentencePieceが主流です。GPTシリーズはBPE、T5はSentencePieceを使用しています。"
    },
    "category": "基礎概念",
    "difficulty": "初級",
    "tags": ["前処理", "NLP基礎", "トークナイザー"],
    "source": "一般的なLLM面接問題"
  },
  {
    "id": "llm_interview_002",
    "question": "Transformerアーキテクチャの主要コンポーネントを説明してください。",
    "answer": {
      "definition": "Transformerは、2017年に「Attention is All You Need」論文で提案された、Self-Attentionメカニズムを基盤とするニューラルネットワークアーキテクチャです。",
      "importance": "RNNやLSTMの逐次処理の制約を克服し、並列処理を可能にすることで、大規模なモデルの学習を実現しました。現代のLLMの基礎となっています。",
      "mechanism": "1. 入力埋め込み層でトークンをベクトル化\n2. 位置エンコーディングを追加\n3. Multi-Head Attentionで文脈を捉える\n4. Feed-Forward Networkで非線形変換\n5. 残差接続とLayer Normalizationで安定化",
      "key_points": [
        "Self-Attention（自己注意）メカニズム",
        "Multi-Head Attention",
        "位置エンコーディング（Positional Encoding）",
        "エンコーダー・デコーダー構造",
        "残差接続（Residual Connection）",
        "Layer Normalization"
      ],
      "examples": [
        "BERT: エンコーダーのみの構造",
        "GPT: デコーダーのみの構造",
        "T5: エンコーダー・デコーダー構造"
      ],
      "applications": "機械翻訳、テキスト生成、要約、質問応答、コード生成など、ほぼすべてのNLPタスクで使用されています。",
      "advantages": "1. 並列処理による高速な学習\n2. 長距離依存関係の効果的な捕捉\n3. 転移学習の容易さ\n4. スケーラビリティ",
      "limitations": "1. 計算量がシーケンス長の2乗に比例\n2. 大量のメモリを必要とする\n3. 位置情報の明示的な埋め込みが必要",
      "formulas": [
        "Attention(Q,K,V) = softmax(QK^T/√d_k)V",
        "MultiHead(Q,K,V) = Concat(head_1,...,head_h)W^O"
      ],
      "related_concepts": "BERT、GPT、T5、Vision Transformer、CLIP",
      "additional_notes": "Transformerの派生モデルには、効率化を図ったLinformer、Performer、Reformerなどがあります。"
    },
    "category": "アーキテクチャ",
    "difficulty": "中級",
    "tags": ["深層学習", "アーキテクチャ", "Attention"],
    "source": "Attention is All You Need (Vaswani et al., 2017)"
  },
  {
    "id": "llm_interview_003",
    "question": "ファインチューニングとは何ですか？事前学習との違いを説明してください。",
    "answer": {
      "definition": "ファインチューニングは、事前学習済みのモデルを特定のタスクやドメインに適応させるために、追加の学習を行うプロセスです。",
      "importance": "大規模な事前学習モデルの知識を活用しながら、少ないデータで特定タスクの性能を向上させることができ、計算資源の節約と高性能を両立できます。",
      "mechanism": "1. 事前学習済みモデルをロード\n2. タスク固有のヘッド（分類層など）を追加\n3. 小さい学習率で全体または一部を再学習\n4. タスク固有のデータで最適化",
      "key_points": [
        "転移学習の一種",
        "少ないデータで高性能を実現",
        "計算コストの削減",
        "ドメイン適応の実現",
        "catastrophic forgettingのリスク"
      ],
      "examples": [
        "BERT-base → 感情分析タスク",
        "GPT-3 → 特定企業のカスタマーサポート",
        "T5 → 医療文書の要約"
      ],
      "applications": "テキスト分類、固有表現認識、質問応答、要約、翻訳など、特定のNLPタスクへの適応に広く使用されます。",
      "advantages": "1. 少ないデータで学習可能\n2. 学習時間の短縮\n3. 高い初期性能\n4. ドメイン特化の性能向上",
      "limitations": "1. 過学習のリスク\n2. 事前学習の知識を忘れる可能性\n3. ハイパーパラメータの調整が必要\n4. データの品質に依存",
      "formulas": [],
      "related_concepts": "転移学習、Few-shot Learning、Prompt Tuning、LoRA、QLoRA",
      "additional_notes": "最近では、パラメータ効率的なファインチューニング手法（PEFT）が注目されており、LoRAやAdapterなどの手法で、少ないパラメータ更新で効果的な適応が可能です。"
    },
    "category": "学習手法",
    "difficulty": "初級",
    "tags": ["学習手法", "転移学習", "実装"],
    "source": "一般的なLLM面接問題"
  },
  {
    "id": "llm_interview_004",
    "question": "RAG（Retrieval-Augmented Generation）について説明してください。",
    "answer": {
      "definition": "RAGは、外部の知識ベースから関連情報を検索し、その情報を活用して生成を行う手法です。検索と生成を組み合わせることで、より正確で最新の情報に基づいた回答を生成します。",
      "importance": "LLMの知識カットオフ問題を解決し、ハルシネーションを減少させ、最新情報や専門知識へのアクセスを可能にします。",
      "mechanism": "1. ユーザーのクエリをエンコード\n2. ベクトルDBから関連文書を検索\n3. 検索結果をコンテキストとして追加\n4. LLMがコンテキストを含めて生成",
      "key_points": [
        "外部知識の活用",
        "リアルタイム情報の反映",
        "ハルシネーションの軽減",
        "ドメイン特化の実現",
        "検索と生成の統合"
      ],
      "examples": [
        "Bing Chat: Web検索結果を活用",
        "企業内チャットボット: 社内文書を検索",
        "医療診断支援: 医学文献データベースを参照"
      ],
      "applications": "質問応答システム、カスタマーサポート、知識ベース検索、ファクトチェック、専門分野のアシスタントなど。",
      "advantages": "1. 最新情報へのアクセス\n2. 事実の正確性向上\n3. 専門知識の活用\n4. 学習不要で知識更新可能",
      "limitations": "1. 検索品質への依存\n2. レイテンシの増加\n3. コンテキスト長の制限\n4. 検索ノイズの影響",
      "formulas": [],
      "related_concepts": "Dense Retrieval、Sparse Retrieval、ベクトルデータベース、Embedding、Re-ranking",
      "additional_notes": "RAGの実装には、FAISS、Pinecone、Weaviateなどのベクトルデータベースが使用されます。また、検索精度向上のため、Hybrid SearchやRe-rankingが併用されることもあります。"
    },
    "category": "応用技術",
    "difficulty": "中級",
    "tags": ["RAG", "検索", "生成", "応用"],
    "source": "RAG論文 (Lewis et al., 2020)"
  },
  {
    "id": "llm_interview_005",
    "question": "BLEUスコアとROUGEスコアの違いを説明してください。",
    "answer": {
      "definition": "BLEUとROUGEは、生成されたテキストの品質を評価する自動評価指標です。BLEUは主に精度（Precision）を、ROUGEは主に再現率（Recall）を重視します。",
      "importance": "人手評価のコストを削減し、モデルの性能を定量的に比較するために不可欠です。特に機械翻訳や要約タスクで広く使用されています。",
      "mechanism": "BLEU: n-gramの一致率を計算し、短文ペナルティを適用\nROUGE: 参照文と生成文のn-gram、最長共通部分列、スキップバイグラムの重なりを計算",
      "key_points": [
        "BLEUは精度ベース",
        "ROUGEは再現率ベース",
        "n-gram単位での評価",
        "複数の参照文に対応",
        "言語依存性がある"
      ],
      "examples": [
        "BLEU-4: 1〜4-gramを考慮",
        "ROUGE-N: n-gramベースの評価",
        "ROUGE-L: 最長共通部分列",
        "ROUGE-W: 重み付き最長共通部分列"
      ],
      "applications": "BLEU: 機械翻訳の評価\nROUGE: 要約タスクの評価\n両方: テキスト生成全般の評価",
      "advantages": "1. 自動計算可能\n2. 言語非依存（ある程度）\n3. 再現性が高い\n4. 高速な評価",
      "limitations": "1. 意味的な正しさを評価できない\n2. 文法的正しさを考慮しない\n3. 同義語を考慮しない\n4. 人間の評価との相関が完全ではない",
      "formulas": [
        "BLEU = BP × exp(Σ(w_n × log p_n))",
        "ROUGE-N = Σ(match(n-gram)) / Σ(count(n-gram))"
      ],
      "related_concepts": "METEOR、BERTScore、BLEURT、人手評価、意味的類似度",
      "additional_notes": "最近では、BERTScoreなどの埋め込みベースの評価指標が提案され、意味的な類似性も考慮できるようになってきています。"
    },
    "category": "評価指標",
    "difficulty": "中級",
    "tags": ["評価", "メトリクス", "NLP"],
    "source": "BLEU (Papineni et al., 2002), ROUGE (Lin, 2004)"
  },
  {
    "id": "llm_interview_006",
    "question": "Attention機構における計算量の問題と、その解決策について説明してください。",
    "answer": {
      "definition": "標準的なSelf-Attentionの計算量はO(n²)であり、シーケンス長nに対して2乗で増加します。これは長い文書を処理する際の大きなボトルネックとなります。",
      "importance": "長文処理、大規模モデルの学習、リアルタイム推論において、計算効率は実用性を左右する重要な要素です。",
      "mechanism": "標準Attention: すべてのトークンペアの注意重みを計算\n効率的Attention: スパース性、低ランク近似、局所性などを利用して計算を削減",
      "key_points": [
        "メモリ使用量もO(n²)",
        "長文処理の制約",
        "学習・推論速度への影響",
        "近似手法のトレードオフ",
        "ハードウェア最適化の重要性"
      ],
      "examples": [
        "Sparse Transformer: 固定パターンのスパースAttention",
        "Linformer: 低ランク近似でO(n)を実現",
        "Flash Attention: メモリアクセスパターンの最適化",
        "Sliding Window Attention: 局所的な窓での計算"
      ],
      "applications": "長文書処理、文書要約、コード生成、対話システムなど、長いコンテキストを扱うすべてのタスク。",
      "advantages": "効率的手法により：\n1. より長い文書の処理が可能\n2. 学習・推論の高速化\n3. メモリ使用量の削減\n4. より大きなバッチサイズ",
      "limitations": "1. 近似による精度低下の可能性\n2. 実装の複雑さ\n3. タスクによって最適な手法が異なる\n4. ハードウェア依存性",
      "formulas": [
        "Standard: O(n² × d)",
        "Linformer: O(n × k × d)",
        "Local Attention: O(n × w × d)"
      ],
      "related_concepts": "Efficient Transformers、Long-context Models、Memory-efficient Training、Gradient Checkpointing",
      "additional_notes": "最新の研究では、Flash Attention v2やPagedAttentionなど、ハードウェアレベルの最適化も含めた手法が開発されています。"
    },
    "category": "実装技術",
    "difficulty": "上級",
    "tags": ["最適化", "計算効率", "Attention"],
    "source": "Efficient Transformers Survey (Tay et al., 2020)"
  },
  {
    "id": "llm_interview_007",
    "question": "LLMにおけるバイアスの問題と対策について説明してください。",
    "answer": {
      "definition": "LLMのバイアスとは、学習データに含まれる偏見や不公平性がモデルの出力に反映される問題です。性別、人種、宗教などに関する偏見が含まれることがあります。",
      "importance": "AIシステムの公平性と信頼性を確保し、社会的な害を防ぐために重要です。特に採用、融資、医療診断などの意思決定に使用される場合は深刻な影響があります。",
      "mechanism": "1. 学習データの偏り\n2. データ収集プロセスのバイアス\n3. アノテーションのバイアス\n4. モデルアーキテクチャの影響\n5. 評価指標の偏り",
      "key_points": [
        "データバイアスの特定と測定",
        "公平性の定義の多様性",
        "バイアス緩和手法",
        "継続的なモニタリング",
        "多様なステークホルダーの関与"
      ],
      "examples": [
        "性別バイアス: 「看護師=女性」の関連付け",
        "人種バイアス: 特定の名前と否定的属性の関連",
        "言語バイアス: 少数言語での性能低下"
      ],
      "applications": "採用支援システム、信用評価、医療診断支援、教育支援、コンテンツモデレーションなど、社会的影響の大きい分野。",
      "advantages": "バイアス対策により：\n1. より公平なAIシステム\n2. 社会的信頼の向上\n3. 法的リスクの軽減\n4. より広いユーザー層への対応",
      "limitations": "1. 完全なバイアス除去は困難\n2. 公平性の定義の曖昧さ\n3. トレードオフの存在\n4. 文化的文脈の考慮が必要",
      "formulas": [],
      "related_concepts": "Fairness、Debiasing、Responsible AI、AI Ethics、Adversarial Debiasing",
      "additional_notes": "バイアス対策には、データ拡張、再重み付け、敵対的学習、事後処理など様々な手法があります。また、Red Teamingやバイアス監査も重要です。"
    },
    "category": "倫理・社会的影響",
    "difficulty": "中級",
    "tags": ["倫理", "バイアス", "公平性", "AI安全性"],
    "source": "AI倫理ガイドライン各種"
  },
  {
    "id": "llm_interview_008",
    "question": "Few-shot LearningとZero-shot Learningの違いを説明してください。",
    "answer": {
      "definition": "Zero-shot Learningは訓練時に見たことがないタスクを例示なしで実行する能力、Few-shot Learningは少数の例（通常1-5個）を与えてタスクを実行する能力です。",
      "importance": "大規模なラベル付きデータが不要で、新しいタスクへの迅速な適応が可能になり、LLMの汎用性と実用性を大幅に向上させます。",
      "mechanism": "Zero-shot: タスク記述のみでプロンプトを構成\nFew-shot: タスク記述と少数の入出力例をプロンプトに含める（In-context Learning）",
      "key_points": [
        "事前学習での知識活用",
        "プロンプトエンジニアリングの重要性",
        "タスク汎化能力",
        "例示の選択と順序の影響",
        "モデルサイズとの相関"
      ],
      "examples": [
        "Zero-shot: 「次の文をフランス語に翻訳してください：」",
        "One-shot: 例を1つ示してから翻訳を要求",
        "Few-shot: 3-5個の翻訳例を示してから要求"
      ],
      "applications": "テキスト分類、感情分析、翻訳、要約、質問応答など、ほぼすべてのNLPタスクで活用可能。",
      "advantages": "1. ラベル付きデータ不要（Zero-shot）または少量で済む\n2. 新タスクへの迅速な適応\n3. ファインチューニング不要\n4. 柔軟なタスク定義",
      "limitations": "1. 複雑なタスクでは性能が劣る\n2. プロンプトの設計に依存\n3. 推論時の計算コスト\n4. 一貫性の保証が困難",
      "formulas": [],
      "related_concepts": "In-context Learning、Prompt Engineering、Chain-of-Thought、Instruction Tuning",
      "additional_notes": "GPT-3以降、Few-shot能力が大幅に向上しました。Chain-of-Thought promptingなどの手法により、推論タスクでも高い性能を示すようになっています。"
    },
    "category": "学習手法",
    "difficulty": "中級",
    "tags": ["学習パラダイム", "プロンプト", "汎化"],
    "source": "GPT-3論文 (Brown et al., 2020)"
  },
  {
    "id": "llm_interview_009",
    "question": "Embeddingとは何ですか？Word2VecとTransformerベースのEmbeddingの違いは？",
    "answer": {
      "definition": "Embeddingは、単語やトークンを固定長の密なベクトル表現に変換する技術です。意味的に類似した単語は、ベクトル空間上で近い位置に配置されます。",
      "importance": "テキストを数値表現に変換することで、ニューラルネットワークでの処理が可能になり、意味的な類似性や関係性を捉えることができます。",
      "mechanism": "Word2Vec: 周辺単語からターゲット単語を予測（CBOW）または逆（Skip-gram）\nTransformer: 文脈を考慮した動的なEmbeddingを生成",
      "key_points": [
        "静的 vs 文脈依存Embedding",
        "次元数とモデル性能",
        "事前学習の重要性",
        "類似度計算への応用",
        "下流タスクへの転移"
      ],
      "examples": [
        "Word2Vec: 'king' - 'man' + 'woman' ≈ 'queen'",
        "BERT: 'bank'が文脈により異なるベクトルに",
        "Sentence-BERT: 文全体のEmbedding"
      ],
      "applications": "意味検索、類似度計算、クラスタリング、推薦システム、異常検知など。",
      "advantages": "文脈依存Embeddingの利点：\n1. 多義語の扱い\n2. 文レベルの意味捕捉\n3. より豊かな表現力\n4. 下流タスクでの高性能",
      "limitations": "1. 計算コストの増加（文脈依存）\n2. 次元数の選択\n3. OOV問題（Word2Vec）\n4. 解釈性の欠如",
      "formulas": [
        "cosine_similarity = (a·b)/(||a||×||b||)",
        "Word2Vec objective: maximize Σlog P(w_o|w_i)"
      ],
      "related_concepts": "Word2Vec、GloVe、FastText、BERT Embeddings、Sentence Transformers",
      "additional_notes": "最新のEmbeddingモデルでは、Contrastive Learningを用いて、より良い表現を学習しています。OpenAI Embeddingsやtext-embedding-ada-002などが実用的に使われています。"
    },
    "category": "基礎概念",
    "difficulty": "初級",
    "tags": ["Embedding", "表現学習", "NLP基礎"],
    "source": "Word2Vec (Mikolov et al., 2013)"
  },
  {
    "id": "llm_interview_010",
    "question": "モデルの量子化（Quantization）について説明してください。",
    "answer": {
      "definition": "量子化は、モデルの重みや活性化を低精度（例：32bit→8bit）で表現することで、モデルサイズを削減し、推論を高速化する技術です。",
      "importance": "大規模LLMをエッジデバイスやリソース制限環境で実行可能にし、推論コストを大幅に削減できます。",
      "mechanism": "1. 重みの値域を分析\n2. 量子化スキームの選択（uniform/non-uniform）\n3. スケールとゼロポイントの計算\n4. 低精度表現への変換\n5. 必要に応じて再学習",
      "key_points": [
        "精度と性能のトレードオフ",
        "Post-training vs Quantization-aware training",
        "INT8、INT4、混合精度",
        "キャリブレーションの重要性",
        "ハードウェアサポート"
      ],
      "examples": [
        "GPTQ: 4bit量子化でGPTモデルを圧縮",
        "bitsandbytes: 8bit/4bit量子化ライブラリ",
        "ONNX Runtime: 様々な量子化オプション"
      ],
      "applications": "モバイルアプリ、エッジAI、大規模モデルのサービング、リアルタイム推論システム。",
      "advantages": "1. モデルサイズを1/4〜1/8に削減\n2. 推論速度の向上\n3. メモリ使用量の削減\n4. 消費電力の削減",
      "limitations": "1. 精度の低下（特に極端な量子化）\n2. 量子化が困難な層の存在\n3. ハードウェア依存性\n4. 追加の最適化作業が必要",
      "formulas": ["q = round(r/S) + Z", "r = S(q - Z)"],
      "related_concepts": "知識蒸留、プルーニング、モデル圧縮、Mixed Precision Training",
      "additional_notes": "最新の研究では、1bit（バイナリ）量子化やTernary量子化なども研究されています。また、量子化とLoRAを組み合わせたQLoRAも注目されています。"
    },
    "category": "実装技術",
    "difficulty": "上級",
    "tags": ["最適化", "モデル圧縮", "推論"],
    "source": "量子化関連論文各種"
  },
  {
    "id": "llm_interview_011",
    "question": "Instruction TuningとRLHF（人間のフィードバックによる強化学習）の関係を説明してください。",
    "answer": {
      "definition": "Instruction Tuningは指示に従うようモデルを訓練する手法で、RLHFはその一種として人間の選好を報酬信号として使用し、強化学習でモデルを最適化します。",
      "importance": "LLMをより有用で、安全で、人間の意図に沿った出力を生成するように調整でき、ChatGPTなどの成功の鍵となっています。",
      "mechanism": "1. SFT（Supervised Fine-Tuning）で初期調整\n2. 人間が応答をランク付け\n3. 報酬モデルを学習\n4. PPO等でポリシーを最適化\n5. 反復的な改善",
      "key_points": [
        "人間の選好の学習",
        "報酬モデルの設計",
        "PPOアルゴリズムの使用",
        "有用性と無害性のバランス",
        "スケーラビリティの課題"
      ],
      "examples": [
        "ChatGPT: InstructGPTの手法を発展",
        "Claude: Constitutional AIを使用",
        "Llama 2-Chat: 安全性重視のRLHF"
      ],
      "applications": "対話システム、アシスタント、コード生成、創造的な文章作成、教育支援など。",
      "advantages": "1. 人間の意図との整合性向上\n2. 有害な出力の削減\n3. より自然な対話\n4. タスク遂行能力の向上",
      "limitations": "1. 人間のフィードバックのコスト\n2. 報酬ハッキングのリスク\n3. 過度な安全性による有用性低下\n4. バイアスの混入可能性",
      "formulas": ["J(θ) = E[R(s,a) - β×KL(π_θ||π_ref)]"],
      "related_concepts": "SFT、PPO、DPO、Constitutional AI、Red Teaming",
      "additional_notes": "最近では、DPO（Direct Preference Optimization）のような、RLを使わない選好最適化手法も提案されており、より効率的な学習が可能になっています。"
    },
    "category": "学習手法",
    "difficulty": "上級",
    "tags": ["RLHF", "アライメント", "強化学習"],
    "source": "InstructGPT論文 (Ouyang et al., 2022)"
  },
  {
    "id": "llm_interview_012",
    "question": "マルチモーダルLLMについて、その仕組みと課題を説明してください。",
    "answer": {
      "definition": "マルチモーダルLLMは、テキストだけでなく、画像、音声、動画など複数のモダリティを理解し、処理できる大規模言語モデルです。",
      "importance": "人間のようにマルチモーダルな情報を統合的に理解し、より豊かなインタラクションと応用を可能にします。",
      "mechanism": "1. 各モダリティ用のエンコーダー\n2. モダリティ間のアライメント\n3. 統合表現の学習\n4. クロスモーダル注意機構\n5. 統一的なデコーディング",
      "key_points": [
        "モダリティ間の表現整合",
        "大規模なペアデータの必要性",
        "計算コストの増大",
        "ゼロショット能力の獲得",
        "創発的な能力の出現"
      ],
      "examples": [
        "GPT-4V: 画像理解機能を持つGPT-4",
        "CLIP: 画像とテキストの対照学習",
        "Flamingo: 少数例での視覚言語タスク",
        "DALL-E: テキストから画像生成"
      ],
      "applications": "画像キャプション生成、視覚的質問応答、画像生成、動画理解、文書理解（OCR含む）、ロボティクスなど。",
      "advantages": "1. より自然なインタラクション\n2. 豊富なタスクへの対応\n3. コンテキスト理解の向上\n4. 創造的なアプリケーション",
      "limitations": "1. 学習データの収集コスト\n2. 計算資源の大幅な増加\n3. モダリティ間の不均衡\n4. 評価の困難さ",
      "formulas": [],
      "related_concepts": "Vision Transformer、CLIP、Contrastive Learning、Cross-modal Attention",
      "additional_notes": "最新のマルチモーダルLLMでは、任意のモダリティの組み合わせを扱えるAny-to-Anyモデルも研究されています。"
    },
    "category": "応用技術",
    "difficulty": "上級",
    "tags": ["マルチモーダル", "視覚言語モデル", "統合AI"],
    "source": "各種マルチモーダルモデル論文"
  },
  {
    "id": "llm_interview_013",
    "question": "Chain-of-Thought（CoT）プロンプティングについて説明してください。",
    "answer": {
      "definition": "Chain-of-Thoughtプロンプティングは、LLMに段階的な推論過程を明示的に出力させることで、複雑な推論タスクの性能を向上させる手法です。",
      "importance": "数学的推論、論理パズル、多段階の問題解決など、複雑な推論を要するタスクでLLMの性能を大幅に向上させます。",
      "mechanism": "1. 問題を提示\n2. 「段階的に考えてみましょう」等のプロンプト\n3. 中間ステップを生成\n4. 各ステップで推論\n5. 最終回答を導出",
      "key_points": [
        "推論の透明性向上",
        "エラーの特定が容易",
        "Few-shot例の効果",
        "自己一貫性の活用",
        "Zero-shot CoTの可能性"
      ],
      "examples": [
        "数学: 「まず問題を理解し、次に式を立て...」",
        "論理: 「前提1から、次に前提2を考慮すると...」",
        "常識推論: 「この状況では通常...したがって...」"
      ],
      "applications": "数学問題、論理推論、コード生成、複雑な質問応答、計画立案、科学的推論など。",
      "advantages": "1. 複雑な推論の精度向上\n2. 解釈可能性の向上\n3. デバッグの容易さ\n4. 人間との協調作業",
      "limitations": "1. 出力トークン数の増加\n2. 推論時間の延長\n3. 単純なタスクでは過剰\n4. 推論の正しさの保証なし",
      "formulas": [],
      "related_concepts": "Self-Consistency、Tree of Thoughts、ReAct、Least-to-Most Prompting",
      "additional_notes": "最新の研究では、Tree of ThoughtsやGraph of Thoughtsなど、より複雑な推論構造を活用する手法も提案されています。"
    },
    "category": "応用技術",
    "difficulty": "中級",
    "tags": ["プロンプティング", "推論", "Few-shot"],
    "source": "Chain-of-Thought論文 (Wei et al., 2022)"
  },
  {
    "id": "llm_interview_014",
    "question": "LLMの安全性確保のためのRed Teamingについて説明してください。",
    "answer": {
      "definition": "Red Teamingは、悪意ある使用や有害な出力を意図的に引き出そうとすることで、LLMの脆弱性や安全性の問題を発見・評価する手法です。",
      "importance": "LLMの実世界での展開前に、潜在的な害やリスクを特定し、対策を講じることで、より安全で信頼性の高いシステムを構築できます。",
      "mechanism": "1. 攻撃シナリオの設計\n2. 敵対的プロンプトの作成\n3. モデルの応答を評価\n4. 脆弱性の文書化\n5. 緩和策の実装と再評価",
      "key_points": [
        "多様な攻撃ベクトル",
        "自動化と人手の組み合わせ",
        "継続的な評価プロセス",
        "倫理的考慮事項",
        "緩和策とのバランス"
      ],
      "examples": [
        "脱獄（Jailbreaking）攻撃",
        "有害コンテンツの生成誘導",
        "個人情報の抽出試行",
        "バイアスの増幅テスト"
      ],
      "applications": "商用LLMの展開前評価、規制遵守の確認、セキュリティ監査、継続的な安全性モニタリング。",
      "advantages": "1. 事前のリスク特定\n2. 安全性の定量的評価\n3. 防御策の開発\n4. ユーザー信頼の向上",
      "limitations": "1. 完全な網羅は不可能\n2. 新しい攻撃手法の出現\n3. 過度な制限のリスク\n4. コストと時間の投資",
      "formulas": [],
      "related_concepts": "Adversarial Prompting、Safety Filters、Constitutional AI、Robustness Testing",
      "additional_notes": "Red Teamingは継続的なプロセスであり、新しい攻撃手法や使用パターンに対応するため、定期的な更新が必要です。自動化ツールと人間の創造性を組み合わせることが効果的です。"
    },
    "category": "倫理・社会的影響",
    "difficulty": "上級",
    "tags": ["安全性", "セキュリティ", "評価", "リスク管理"],
    "source": "各社のRed Teaming実践報告"
  },
  {
    "id": "llm_interview_015",
    "question": "Perplexityとは何ですか？言語モデルの評価における役割を説明してください。",
    "answer": {
      "definition": "Perplexityは、言語モデルがテストデータをどれだけよく予測できるかを示す指標で、モデルの予測の不確実性を表します。値が低いほど良いモデルとされます。",
      "importance": "言語モデルの品質を定量的に評価し、異なるモデルやハイパーパラメータ設定を比較するための標準的な指標です。",
      "mechanism": "テストセットの各トークンに対する予測確率の幾何平均の逆数として計算され、クロスエントロピー損失と密接に関連しています。",
      "key_points": [
        "確率的な解釈が可能",
        "データセット依存性",
        "トークナイザーの影響",
        "下流タスク性能との相関",
        "比較時の注意点"
      ],
      "examples": [
        "GPT-2: WikiText-103で〜20のPerplexity",
        "より小さいモデル: 50-100程度",
        "ドメイン特化モデル: 該当ドメインで低いPerplexity"
      ],
      "applications": "モデル選択、ハイパーパラメータチューニング、学習の収束判定、ドメイン適応の評価など。",
      "advantages": "1. 計算が簡単\n2. 理論的な基盤\n3. 自動計算可能\n4. 言語非依存",
      "limitations": "1. 短い文で不安定\n2. 生成品質を直接反映しない\n3. トークナイザー依存\n4. ドメイン間で比較困難",
      "formulas": ["PPL = exp(-1/N × Σlog P(w_i|w_{<i}))", "PPL = exp(H(P))"],
      "related_concepts": "Cross-entropy、Bits per character、Log-likelihood、Entropy",
      "additional_notes": "Perplexityは言語モデルの固有の評価指標ですが、実際のタスク性能とは必ずしも相関しないため、タスク固有の評価も重要です。"
    },
    "category": "評価指標",
    "difficulty": "初級",
    "tags": ["評価", "言語モデル", "メトリクス"],
    "source": "言語モデル基礎理論"
  }
]
