id: "Q18"
question: "過学習とは何か、LLMでどのように軽減できるか？"
answer: "過学習は、モデルが訓練データを記憶し、汎化に失敗する場合に発生します。軽減策には、L1/L2ペナルティがモデルを簡素化する正則化、訓練中にランダムにニューロンを無効にするドロップアウト、検証性能が横ばいになったときに訓練を停止する早期停止があり、これらの技術により、見たことのないデータへの堅牢な汎化を確保します。"