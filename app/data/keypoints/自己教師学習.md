---
title: 自己教師学習
contexts:
  - ai
---

<Context name="ai">

## 自己教師学習

自己教師学習（Self-supervised Learning）は、**「データ自体から教師信号を生成する」**学習パラダイムで、明示的なラベル付きデータなしに、入力データの構造的特性を活用して有用な表現を学習する革新的な手法です。

### 基本原理と応用可能性

自己教師学習の核心は、**プリテキストタスク**の設計にあります。これは、データに人工的な「隠蔽」や「変換」を施し、それを復元する課題を作ることです：

**言語領域でのプリテキストタスク例：**
- **マスク言語モデル**：単語を隠して予測させる
- **次文予測**：文章の続きを予測させる
- **文章順序予測**：シャッフルした文章の順序を復元させる

**画像領域でのプリテキストタスク例：**
- **画像パッチの回転予測**：回転角度を予測させる
- **欠損部分の補完**：画像の一部を隠して復元させる
- **色彩情報の復元**：グレースケール画像から色を予測させる

### 長期記憶への定着要素

自己教師学習を理解する鍵は**「隠れた構造の発見」**という概念です。人間の学習プロセスと類似しており、私たちは世界を観察する際、明示的な教師なしに**パターンや規則性を自然に発見**します。

この学習方法は、「なぜそうなるのか」を理解することで構造を把握するため、得られた知識は汎用性が高く、様々な下流タスクに応用できます。

### 他の知識との関連性

自己教師学習は多くの重要な概念と関連しています：
- **事前学習**：大規模データでの自己教師学習による基盤モデル構築
- **表現学習**：データの本質的な特徴を捉えた埋め込み表現の獲得
- **転移学習**：事前学習した表現の下流タスクへの活用
- **マルチモーダル学習**：異なるモダリティ間の対応関係の学習
- **対照学習**：類似・非類似データペアを用いた表現学習

### 「なぜ？」への回答

**なぜ自己教師学習が重要なのか？**
従来の教師あり学習では、大量のラベル付きデータが必要でした。しかし、ラベル付けは時間とコストがかかり、スケーラビリティに限界があります。自己教師学習により、**無限に存在する無ラベルデータから有用な知識を抽出**できるようになりました。

また、自己教師学習で学習した表現は、人間が明示的に設計した特徴量では捉えきれない、データの深い構造的特性を反映するため、様々なタスクに対して高い汎用性と性能を示します。

</Context>

