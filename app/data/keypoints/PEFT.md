---
title: PEFT
contexts:
  - ai
---

<Context name="ai">

## PEFT

PEFT（Parameter-Efficient Fine-Tuning）は、大規模言語モデルを少ないパラメータで効率的にファインチューニングする手法群の総称で、計算資源の民主化を実現する重要な技術体系です。

### なぜPEFTが必要なのか

GPT-3やLLaMAのような巨大モデルは、全パラメータのファインチューニングに膨大なGPUメモリと計算時間を要求します。PEFTは、性能を維持しながら学習パラメータを99%以上削減し、一般的なGPUでも大規模モデルの適応を可能にします。

### コア原理：選択的パラメータ更新

PEFTの本質は「どのパラメータを更新すべきか」の戦略的選択です：

1. **追加モジュール方式**: 小さな学習可能層を挿入（LoRA、Adapter）
2. **プロンプト方式**: 入力に学習可能トークンを追加（Prefix-tuning、P-tuning）
3. **選択的更新**: 既存パラメータの一部のみ更新（BitFit）
4. **再パラメータ化**: 低次元表現での学習（LoRA、IA3）

### 主要なPEFT手法の比較

**LoRA（Low-Rank Adaptation）**：
- 低ランク行列で重み更新を表現
- 推論時のオーバーヘッドなし
- 最も広く採用されている手法

**Adapter Layers**：
- 各Transformer層に小さなFFNを挿入
- シンプルで効果的
- 推論時に若干の遅延

**Prefix Tuning**：
- 仮想的なプレフィックストークンを学習
- タスク指示の自動学習
- 入力長制限への影響

**IA3（Infused Adapter by Inhibiting and Amplifying）**：
- スケーリングベクトルのみ学習
- 極めて少ないパラメータ
- LoRAと同等の性能

### 他の知識との関連

- **転移学習**: 事前学習済みモデルの知識活用
- **マルチタスク学習**: 複数タスクの同時最適化
- **モデル圧縮**: 量子化・蒸留との組み合わせ
- **フェデレーテッド学習**: 分散環境での学習

### 長期記憶のための概念理解

PEFTを「専門医の追加トレーニング」として理解しましょう。総合医（基礎モデル）に、特定分野の専門知識（タスク特化）を効率的に追加する方法論です。

### 実践的な選択指針

**タスクによる使い分け**：
- 文体適応→LoRA（表現の微調整）
- 新知識注入→Adapter（新しい変換学習）
- タスク指示→Prefix Tuning（入力文脈の拡張）

**リソースによる選択**：
- 極小メモリ→IA3、BitFit
- 標準的な環境→LoRA
- 柔軟性重視→Adapter Layers

### 応用と将来展望

**現在の応用**：
- ChatGPTのような対話システムのカスタマイズ
- ドメイン特化型AIの開発
- エッジデバイスでのAI実行

**今後の発展**：
- 複数PEFT手法の組み合わせ
- 自動的な手法選択
- 継続学習への応用

PEFTは「大規模AIの個人利用」を現実のものとし、AIの民主化における最重要技術の一つとなっています。

</Context>

