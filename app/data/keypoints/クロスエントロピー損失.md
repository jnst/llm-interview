---
title: クロスエントロピー損失
contexts:
  - optimization
---

<Context name="optimization">

## クロスエントロピー損失

クロスエントロピー損失は、分類問題において予測確率分布と真の確率分布の差異を測定する最適化の中核的な損失関数です。

### 本質的な理解

クロスエントロピー損失は「情報理論的な距離」を表現します。正解ラベルに対する予測確率が高いほど損失は小さく、低いほど損失は大きくなります。これは「正解に対する確信度の不足を罰する」という直感的な仕組みです。

### 数学的構造と応用

多クラス分類では、損失は以下の形式になります：
```
L = -∑ᵢ yᵢ log(ŷᵢ)
```
ここで、yᵢは正解ラベル、ŷᵢは予測確率です。対数関数により、確率が0に近づくほど損失が急激に増加し、モデルに強い学習信号を与えます。

### 長期記憶への定着

クロスエントロピー損失は「予測の確信度に対する罰則」として記憶すると効果的です。「間違いを犯すことよりも、間違いに確信を持つことを強く罰する」という特性があります。

### 他の概念との関連

- **ソフトマックス関数**: 出力を確率分布に変換
- **最尤推定**: 統計的な理論的基盤
- **勾配降下法**: 損失最小化のための最適化手法
- **正則化**: 過学習防止との組み合わせ

### なぜクロスエントロピーが選ばれるか

1. **確率解釈**: 出力を確率として解釈可能
2. **凸性**: 最適化が容易
3. **勾配特性**: 予測が大きく外れた時に強い学習信号
4. **理論的基盤**: 最尤推定との一致

この理解により、なぜ分類問題でクロスエントロピー損失が標準的に使用されるかが明確になります。

</Context>

