---
title: トークン化
contexts:
  - ai
---

<Context name="ai">
## トークン化

トークン化は、自然言語処理において「人間の言語をコンピュータが理解できる単位に分解」する基本的な前処理技術です。文章を単語、サブワード、文字などの意味のある最小単位（トークン）に分割し、AIモデルが処理できる形式に変換します。

### なぜトークン化が重要なのか

コンピュータは自然言語を直接理解することができません。トークン化は「言語とアルゴリズムの橋渡し」として機能します：

- **構造化**: 連続的な文字列を離散的な単位に分割
- **標準化**: 異なる表現形式を統一的に処理
- **効率化**: 計算処理に適した形式への変換
- **語彙管理**: 有限の語彙集合での表現を可能にする

### トークン化の種類と特徴

**1. 単語レベルトークン化**
- 空白や句読点で単語を分割
- 直感的で理解しやすい
- 未知語（OOV）問題が発生しやすい

**2. サブワードトークン化**
- BPE（Byte Pair Encoding）、WordPiece、SentencePieceなど
- 未知語問題を解決し、語彙サイズを制御
- 現代の言語モデルで主流

**3. 文字レベルトークン化**
- 各文字を独立したトークンとして処理
- 未知語問題は発生しないが、文脈の理解が困難

### 実践的な応用のポイント

トークン化の設計では以下の要素のバランスが重要です：

- **語彙サイズ**: 小さすぎると表現力不足、大きすぎると計算コスト増
- **言語特性**: 日本語の場合、分かち書きの問題を考慮
- **ドメイン特性**: 専門用語や固有名詞の適切な分割
- **計算効率**: モデルの処理速度とメモリ使用量への影響

### 他の技術との関連

- **エンベディング**: トークンを数値ベクトルに変換する次のステップ
- **語彙管理**: トークン-ID変換辞書の構築と管理
- **前処理パイプライン**: 正規化、クリーニングとの連携
- **バイトペアエンコーディング**: 効率的なサブワード分割手法
- **位置エンコーディング**: トランスフォーマーでのトークン位置情報

### 新しい問題への対応

トークン化の理解により、以下の問題に対応できます：

- **多言語対応**: 異なる言語特性に適したトークン化手法の選択
- **ドメイン適応**: 新しい専門分野での語彙構築
- **効率化**: 計算資源の制約に応じた最適化
- **品質向上**: 下流タスクの性能向上のためのトークン化戦略

トークン化は「見えない基盤技術」として、AIシステムの性能を根本的に左右する重要な要素です。
</Context>

