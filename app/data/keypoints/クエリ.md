---
title: クエリ
contexts:
  - transformer
  - rag
---

<Context name="transformer">

## クエリ

Transformerモデルにおけるクエリ（Query）は、Attentionメカニズムの核心部分で、「何に注意を向けるか」を決定する学習可能な表現です。

### 本質的な理解

クエリは、入力シーケンスの各位置において「他のどの位置の情報が重要か」を決定するための質問として機能します。これは人間が文章を読むときに「この単語の意味を理解するために、他のどの単語を参照すべきか」と考える過程と類似しています。

### 数学的構造と応用

クエリベクトルは入力の線形変換によって作られ、キー（Key）との内積計算によってAttention重みを算出します。この仕組みにより、モデルは文脈に応じて動的に関連情報を選択できるようになります。

### 長期記憶への定着

クエリは「動的な検索キー」として記憶すると効果的です。データベースのクエリと異なり、Transformerのクエリは学習を通じて最適化され、より効果的な注意パターンを学習します。

### 他の概念との関連

- **キー・バリュー**: クエリと協働してAttentionを実現
- **マルチヘッドアテンション**: 複数のクエリ空間で並列処理
- **位置エンコーディング**: クエリに位置情報を付与

この理解により、Transformerが言語の長距離依存関係を捉える理由が明確になります。

</Context>

<Context name="rag">

## クエリ

RAG（Retrieval-Augmented Generation）におけるクエリは、外部知識ベースから関連情報を取得するための検索要求であり、生成品質を決定する重要な要素です。

### 本質的な理解

RAGのクエリは「知識の橋渡し」として機能します。ユーザーの質問や生成タスクを、膨大な文書コレクションから最も関連性の高い情報を特定するための検索信号に変換します。

### 実用的な応用

効果的なクエリ設計により、RAGシステムは：
- 最新情報の取得（訓練データにない情報）
- 専門分野の詳細な知識の活用
- 事実確認と根拠の提供
- 幻覚（hallucination）の軽減

### 長期記憶への定着

RAGクエリは「質問の翻訳機」として記憶すると理解しやすくなります。自然言語の質問を、検索エンジンが理解できる形式に変換し、適切な文書を見つけ出す役割を担います。

### 他の概念との関連

- **埋め込み（Embedding）**: クエリのベクトル表現
- **類似度検索**: クエリと文書の関連性評価
- **リランキング**: 検索結果の再順序付け
- **プロンプトエンジニアリング**: 効果的なクエリ構築

この理解により、RAGシステムが知識集約型タスクで高性能を発揮する仕組みが明確になります。

</Context>
