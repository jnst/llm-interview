---
title: クエリ
contexts:
  - transformer
  - rag
---

## クエリ

<Context name="transformer">

### 概要と基本原理
Transformer文脈でのクエリは、アテンション機構における重要な要素の一つです。「何に注意を向けるか」を決定する質問の役割を果たし、キー（Key）と値（Value）と組み合わせて、入力情報の中から関連性の高い部分を特定します。これは図書館で特定の本を探すときの「検索条件」のような働きをします。

### 技術的特徴
クエリは入力データから線形変換により生成されるベクトルで、キーとの内積計算によってアテンションスコアを算出します。この仕組みにより、モデルは各位置の情報がどの程度重要かを動的に判断できます。マルチヘッドアテンションでは、異なる表現空間で複数のクエリを並列処理することで、多様な観点から情報を抽出します。

### 応用可能性
クエリの概念は、セルフアテンション、クロスアテンション、マスクドアテンションなど、様々なアテンション機構で応用されます。機械翻訳では文脈に応じた単語選択、文書要約では重要な情報の抽出、画像認識では関連する視覚的特徴の特定に活用されます。

### 他の技術との関連
クエリはキーと値と三位一体の関係にあり、この組み合わせがTransformerの核心です。また、RNNやCNNとは異なり、位置に依存しない並列処理を可能にし、長距離依存関係の学習を効率化します。

### なぜ重要なのか
クエリが重要な理由は、「選択的注意」という人間の認知機能をモデル化したことです。膨大な情報の中から関連性の高い部分を効率的に抽出することで、モデルの表現能力と計算効率を両立させています。

</Context>

<Context name="rag">

### 概要と基本原理
RAG（Retrieval-Augmented Generation）文脈でのクエリは、外部知識ベースから関連情報を検索するための検索クエリです。ユーザーの質問や生成タスクに基づいて、最も関連性の高い文書や情報を特定するための「検索キーワード」の役割を果たします。

### 技術的特徴
RAGにおけるクエリは、自然言語の質問を高次元ベクトル空間に埋め込んで表現されます。このクエリベクトルと事前にインデックス化された文書ベクトルとの類似度計算により、関連文書を効率的に検索します。密な検索（Dense Retrieval）手法により、意味的類似性に基づいた高精度な検索を実現します。

### 応用可能性
RAGのクエリは、質問応答システム、文書要約、事実確認、知識に基づく対話システムなど、外部知識が必要なタスクで威力を発揮します。リアルタイムで最新情報を取得し、生成される回答の正確性と信頼性を向上させます。

### 他の技術との関連
RAGのクエリは、情報検索技術とLLMの生成技術を橋渡しする重要な要素です。BM25やTF-IDFなどの従来の検索手法と、BERTやSentence-BERTなどの深層学習による意味検索を組み合わせることで、より効果的な検索を実現します。

### なぜ重要なのか
RAGにおけるクエリが重要な理由は、LLMの「知識の限界」を補完することです。モデルのパラメータに格納された静的な知識ではなく、動的に更新可能な外部知識を活用することで、より正確で最新の情報に基づく回答を生成できます。

</Context>
