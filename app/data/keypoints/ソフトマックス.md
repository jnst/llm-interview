---
title: ソフトマックス
contexts:
  - math
---

<Context name="math">

## ソフトマックス

ソフトマックス関数は、実数ベクトルを確率分布に変換する数学的な関数であり、機械学習における多クラス分類の基盤となる重要な概念です。

### 本質的な理解

ソフトマックスは「競合する選択肢の確率化」を行います。複数の選択肢があるとき、それぞれの「強さ」を相対的な確率に変換します。これは、異なる強度の信号を公平に比較可能な確率形式に正規化する処理です。

### 数学的定義と性質

n次元ベクトルx = (x₁, x₂, ..., xₙ)に対して、ソフトマックス関数は以下のように定義されます：

```
softmax(xᵢ) = exp(xᵢ) / Σⱼ exp(xⱼ)
```

この関数の重要な性質：
1. **正規化**: 全ての出力の合計が1になる
2. **正値性**: 全ての出力が正の値をとる
3. **単調性**: 入力が大きいほど出力も大きくなる
4. **微分可能性**: 勾配計算が可能

### 長期記憶への定着

ソフトマックスは「公平な投票システム」として記憶すると効果的です。複数の候補者（クラス）がいるとき、それぞれの得票数（スコア）を全体に対する得票率（確率）に変換するプロセスと類似しています。

### 他の概念との関連

- **クロスエントロピー損失**: ソフトマックスの出力を用いた損失計算
- **ロジスティック回帰**: 2クラス版のソフトマックス
- **アテンション機構**: 重み計算での使用
- **温度パラメータ**: 確率分布の調整

### なぜソフトマックスが重要か

1. **確率解釈**: 出力を確率として解釈可能
2. **勾配特性**: 学習に適した微分特性
3. **数値的安定性**: 適切な実装で安定した計算
4. **理論的基盤**: 統計学的な理論との整合性

### 実用的な応用

- **画像分類**: 複数クラスの分類確率
- **自然言語処理**: 語彙全体での単語選択確率
- **推薦システム**: アイテムの選択確率
- **強化学習**: 行動選択の確率的政策

### 数値的な考慮事項

実装時には以下の点に注意が必要：
- **オーバーフロー対策**: 大きな値の指数計算
- **アンダーフロー対策**: 小さな値の処理
- **温度スケーリング**: 確率分布の調整

この理解により、機械学習モデルがどのように不確実性を扱い、意思決定を行うかが明確になります。

</Context>

