---
title: 統計的言語モデル
contexts:
  - ai
---

<Context name="ai">

## 統計的言語モデル

統計的言語モデルは、**「言語の確率的性質を数学的にモデル化する」**手法で、大量のテキストデータから言語の統計的パターンを学習し、単語や文の出現確率を予測する自然言語処理の基盤技術です。

### 基本原理と応用可能性

統計的言語モデルの核心は、言語を確率分布P(w₁, w₂, ..., wₙ)として表現することです。この分布は連鎖律により：
P(w₁, w₂, ..., wₙ) = P(w₁) × P(w₂|w₁) × ... × P(wₙ|w₁, ..., wₙ₋₁)

と分解され、各単語の条件付き確率を学習します。

この原理により、以下の応用が可能になります：
- **言語生成**：確率的サンプリングによる文章生成
- **機械翻訳**：翻訳候補の妥当性評価
- **音声認識**：音声から文字への変換における言語制約
- **情報検索**：クエリと文書の類似性計算

### 長期記憶への定着要素

統計的言語モデルを理解する鍵は**「言語の予測可能性」**という概念です。人間は会話や読書の際、文脈から次の単語をある程度予測できます。統計的言語モデルは、この予測能力を大量のデータから学習し、数値化したものです。

N-gramモデル（N個の単語の共起パターン）から始まり、現在のTransformerベースの大規模言語モデルまで、すべて「過去の文脈から次の単語を予測する」という基本原理を共有しています。

### 他の知識との関連性

統計的言語モデルは多くの概念と関連しています：
- **N-gramモデル**：初期の統計的言語モデルの代表例
- **スムージング**：データの希少性問題への対処
- **ニューラル言語モデル**：深層学習による統計的言語モデルの発展
- **事前学習**：大規模統計的言語モデルによる汎用表現学習
- **自己教師学習**：明示的な教師データなしでの統計的パターン学習

### 「なぜ？」への回答

**なぜ統計的言語モデルが重要なのか？**
言語は本質的に確率的な現象です。同じ文脈でも複数の適切な表現が存在し、その選択には統計的な偏りがあります。統計的言語モデルは、この**言語の確率的性質を捉えることで、自然で流暢な言語処理**を可能にします。

また、統計的アプローチにより、明示的なルールを作成することなく、データから自動的に言語パターンを学習できるため、多様な言語や表現スタイルに対応できる汎用性を持ちます。

</Context>

