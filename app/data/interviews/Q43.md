---
id: "Q43"
keywords: ["セルフアテンション","トランスフォーマー","モデル","勾配消失","層正規化","残差接続"]
---

## Question 43

トランスフォーマーは勾配消失問題にどのように対処するか？

## Answer

[トランスフォーマー](../keypoints/トランスフォーマー.md?context=ai)は、順次的な依存関係を避ける[セルフアテンション](../keypoints/セルフアテンション.md?context=ai)、直接的な勾配の流れを可能にする[残差接続](../keypoints/残差接続.md?context=ai)、更新を安定化する[層正規化](../keypoints/層正規化.md?context=ai)によって[勾配消失](../keypoints/勾配消失.md?context=ai)を軽減し、これらはRNNとは異なり、深い[モデル](../keypoints/モデル.md?context=ai)の効果的な訓練を確実にします。
