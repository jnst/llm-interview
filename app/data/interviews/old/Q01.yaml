id: "Q01"
question: "トークン化はどのような処理を伴い、なぜLLMにとって重要なのか？"
answer: "トークン化は、テキストを単語、サブワード、文字などのより小さな単位（トークン）に分割する処理で、例えば「artificial」を「art」「ific」「ial」に分割することなどが含まれます。この処理が重要なのは、LLMが生のテキストではなくトークンの数値表現を処理するためで、トークン化により、モデルは多様な言語を扱い、稀な単語や未知の単語を管理し、語彙サイズを最適化することができ、計算効率とモデル性能を向上させます。"