id: "Q43"
question: "トランスフォーマーは勾配消失問題にどのように対処するか？"
answer: "トランスフォーマーは、順次的な依存関係を避けるセルフアテンション、直接的な勾配の流れを可能にする残差接続、更新を安定化する層正規化によって勾配消失を軽減し、これらはRNNとは異なり、深いモデルの効果的な訓練を確実にします。"