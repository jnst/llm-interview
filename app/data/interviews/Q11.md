---
id: "Q11"
keywords: ["BERT","モデル","事前学習","対話システム","次文予測"]
---

## Question 11

次文予測とは何か、LLMをどのように強化するか？

## Answer

[次文予測](../keypoints/次文予測.md?context=ai)（NSP）は、二つの文が連続しているか無関係かを判断するように[モデル](../keypoints/モデル.md?context=ai)を訓練します。[事前学習](../keypoints/事前学習.md?context=ai)中、[BERT](../keypoints/BERT.md?context=ai)のような[モデル](../keypoints/モデル.md?context=ai)は50%の正例（連続）と50%の負例（ランダム）の文ペアを分類することを学習し、NSPは文の関係を理解することで、[対話システム](../keypoints/対話システム.md?context=ai)や文書要約などのタスクにおける一貫性を向上させます。
